{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b37c210",
   "metadata": {},
   "source": [
    "1. 게임 설정 입력 <br>\n",
    "   ↓ <br> <br>\n",
    "2. GameDifficultyCalculator 초기화 <br>\n",
    "   ├── 모든 실력 수준 (0.1~0.9)에 대해 <br>\n",
    "   ├── 모든 단계 (1~7)별로 <br>\n",
    "   └── 기존 함수들로 성능 미리 계산 <br> \n",
    "   ↓ <br> <br>\n",
    "3. 실제 데이터 입력 → UserPopulationEstimator <br>\n",
    "   ├── 각 단계별 실패율 분석 <br>\n",
    "   ├── 미리 계산된 프로필과 비교 <br>\n",
    "   └── 유저 실력 분포 추정 <br>\n",
    "   ↓ <br> <br>\n",
    "4. AdaptiveMonteCarlo 시뮬레이션 <br>\n",
    "   ├── 추정된 실력 분포로 유저 샘플링 <br>\n",
    "   ├── 미리 계산된 성공률로 빠른 시뮬레이션 <br>\n",
    "   └── 결과 분석 및 난이도 조정 권장 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc62be65",
   "metadata": {},
   "source": [
    "## 현재 게임 규칙\n",
    "\n",
    "1단계2x2 / 총 그림 2개- 기본 카드: 2개- 트릭 카드: 0개제한 시간: 5초성공 리워드: 2원실패 리워드: 1원\n",
    "\n",
    "2단계2x3 / 총 그림 3개- 기본 카드: 3개- 트릭 카드: 0개제한 시간: 7초성공 리워드: 2원\n",
    "\n",
    "3단계3x4 / 총 그림 6개- 기본 카드: 6개- 트릭 카드: 0개제한 시간: 9초성공 리워드: 2원\n",
    "\n",
    "4단계4x4 / 총 그림 8개- 기본 카드: 8개- 트릭 카드: 0개제한 시간: 13초성공 리워드: 2원\n",
    "\n",
    "5단계4x4 / 총 그림 8개- 기본 카드: 6개- 트릭 카드: 2개제한 시간: 15초성공 리워드: 3원\n",
    "\n",
    "6단계4x5 / 총 그림 10개- 기본 카드: 10개- 트릭 카드: 0개제한 시간: 21초성공 리워드: 3원\n",
    "\n",
    "7단계4x5 / 총 그림 10개- 기본 카드: 8개- 트릭 카드: 2개제한 시간: 25초성공 리워드: 6원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a55674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "import sys\n",
    "# 맥과 윈도우 os 판별하고, 시각화에서 한글 꺠지지 않도록 설정하는 코드\n",
    "if sys.platform == 'darwin':\n",
    "    plt.rcParams['font.family'] = 'AppleGothic'\n",
    "else:\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a01f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "from typing import Tuple, Dict, Any, Optional\n",
    "\n",
    "def remove_last_row_column(sparse_matrix):\n",
    "    \"\"\"행렬에서 마지막 행과 열을 제거하는 함수\"\"\"\n",
    "    num_states = sparse_matrix.shape[0]\n",
    "    row_mask = np.ones(sparse_matrix.shape[0], dtype=bool)\n",
    "    row_mask[num_states-1] = False\n",
    "    col_mask = np.ones(sparse_matrix.shape[1], dtype=bool)\n",
    "    col_mask[num_states-1] = False\n",
    "    return sparse_matrix[row_mask][:,col_mask]\n",
    "\n",
    "def _build_matrix_from_adjacency(adjacency_list: Dict, entire_matrix: bool, extra_info: bool):\n",
    "    \"\"\"card_matching.ipynb와 동일한 행렬 구성\"\"\"\n",
    "    num_states = len(adjacency_list)\n",
    "    markov_chain = scipy.sparse.lil_matrix((num_states, num_states))\n",
    "\n",
    "    # Build enumeration for states - card_matching.ipynb와 동일\n",
    "    sorted_keys = sorted(list(adjacency_list.keys()), key=lambda pair: -sum(pair))\n",
    "    keys_to_index = {key: index for index, key in enumerate(sorted_keys)}\n",
    "\n",
    "    for state, neighbors in adjacency_list.items():\n",
    "        adjacency_list[state] = {k: v for k, v in neighbors.items() if v > 1e-10}\n",
    "        for destination, probability in neighbors.items():\n",
    "            markov_chain[(keys_to_index[state], keys_to_index[destination])] = probability\n",
    "    \n",
    "    if not entire_matrix:  # Get block matrix for fundamental matrix calculation\n",
    "        to_return = remove_last_row_column(markov_chain)\n",
    "    else:\n",
    "        to_return = scipy.sparse.csr_matrix(markov_chain)\n",
    "\n",
    "    if extra_info:\n",
    "        return to_return, {\"adjacency_list\": adjacency_list, \"keys_to_index\": keys_to_index, \"sorted_keys\": sorted_keys}\n",
    "    return to_return\n",
    "\n",
    "def get_optimal_baseline_markov_chain(number_of_pairs: int, entire_matrix: bool = False, extra_info: bool = False):\n",
    "    \"\"\"card_matching.ipynb와 동일한 완벽한 기억력 베이스라인\"\"\"\n",
    "    queue = [(0, 2 * number_of_pairs)]\n",
    "    adjacency_list = {}\n",
    "\n",
    "    while queue:\n",
    "        curr_state = queue.pop()\n",
    "        alpha, beta = curr_state\n",
    "    \n",
    "        if alpha < 0 or beta < 0:\n",
    "            continue\n",
    "  \n",
    "        next_states = {}\n",
    "        # card_matching.ipynb의 정확한 로직\n",
    "        if alpha > beta or (alpha + beta) % 2 == 1:  # Know more knowns than unknowns or there is a duplicate in the flipped cards\n",
    "            next_states[(alpha - 1, beta)] = 1  # 완전 기억 케이스\n",
    "        elif alpha == 0 and beta == 0:\n",
    "            next_states[(0, 0)] = 1\n",
    "        elif alpha == beta:\n",
    "            next_states[(max(0, alpha - 1), beta - 1)] = 1\n",
    "        else: \n",
    "            # 완전 기억 케이스 - card_matching.ipynb와 동일\n",
    "            next_states[(alpha - 1, beta - 1)] = alpha / beta \n",
    "            next_states[(alpha + 2, beta - 2)] = (1 - alpha/beta) * (1 - (alpha+1)/(beta-1))\n",
    "            next_states[(alpha + 1, beta - 2)] = (1 - alpha/beta) * (alpha / (beta - 1))\n",
    "            next_states[(alpha, beta - 2)] = (1 - alpha/beta) * 1 / (beta - 1)\n",
    "\n",
    "        # exclude calculating transitions for states with 0 probability to reach\n",
    "        queue.extend(state for state, probability in next_states.items() \n",
    "                    if state not in adjacency_list and probability > 0)\n",
    "        adjacency_list[curr_state] = next_states\n",
    "\n",
    "    # Clear out not possible states\n",
    "    for state, neighbors in adjacency_list.items():\n",
    "        adjacency_list[state] = {k: v for k, v in neighbors.items() if v > 0}\n",
    "\n",
    "    return _build_matrix_from_adjacency(adjacency_list, entire_matrix, extra_info)\n",
    "\n",
    "def get_imperfect_memory_markov_chain(number_of_pairs: int, memory_decay_factor: float = 0.1, \n",
    "                                     entire_matrix: bool = False, extra_info: bool = False):\n",
    "    \"\"\"기억력 저하로 인한 성능 감소 모델 - 턴 수가 증가하도록 설계\"\"\"\n",
    "    queue = [(0, 2 * number_of_pairs)]\n",
    "    adjacency_list = {}\n",
    "\n",
    "    while queue:\n",
    "        curr_state = queue.pop()\n",
    "        alpha, beta = curr_state\n",
    "    \n",
    "        if alpha < 0 or beta < 0:\n",
    "            continue\n",
    "  \n",
    "        next_states = {}\n",
    "        \n",
    "        # 게임 종료 조건들\n",
    "        if alpha == 0 and beta == 0:\n",
    "            next_states[(0, 0)] = 1\n",
    "        elif beta == 0:\n",
    "            next_states[(0, 0)] = 1\n",
    "        elif beta == 1:\n",
    "            next_states[(0, 0)] = 1\n",
    "        elif (alpha + beta) % 2 == 1:\n",
    "            next_states[(max(0, alpha - 1), beta)] = 1\n",
    "        else:\n",
    "            # 기억력 저하 효과 적용\n",
    "            base_success_prob = alpha / beta if alpha <= beta else 0.9\n",
    "            \n",
    "            # memory_decay_factor가 클수록 성능 저하 (더 많은 턴 필요)\n",
    "            degraded_success_prob = base_success_prob * (1 - memory_decay_factor)\n",
    "            \n",
    "            # 매칭 성공 (기억한 정보로 올바른 선택)\n",
    "            success_prob = min(degraded_success_prob, 0.95)  # 최대 95%로 제한\n",
    "            next_states[(max(0, alpha - 1), beta - 2)] = success_prob\n",
    "            \n",
    "            # 실패 케이스들 (기억력 저하로 인한 비효율적 선택)\n",
    "            fail_prob = 1 - success_prob\n",
    "            \n",
    "            if fail_prob > 0:\n",
    "                # 완전 실패: 새로운 정보만 얻고 매칭 실패\n",
    "                next_states[(min(alpha + 2, beta), beta - 2)] = fail_prob * 0.6\n",
    "                \n",
    "                # 부분 실패: 일부 정보만 기억하고 매칭 실패  \n",
    "                next_states[(min(alpha + 1, beta), beta - 2)] = fail_prob * 0.3\n",
    "                \n",
    "                # 정보 손실: 기존 정보도 일부 잃음\n",
    "                next_states[(max(0, alpha - 1), beta)] = fail_prob * 0.1\n",
    "\n",
    "        queue.extend(state for state, probability in next_states.items() \n",
    "                    if state not in adjacency_list and probability > 0)\n",
    "        adjacency_list[curr_state] = next_states\n",
    "\n",
    "    # 0 확률 상태 제거\n",
    "    for state, neighbors in adjacency_list.items():\n",
    "        adjacency_list[state] = {k: v for k, v in neighbors.items() if v > 0}\n",
    "\n",
    "    return _build_matrix_from_adjacency(adjacency_list, entire_matrix, extra_info)\n",
    "\n",
    "def get_case_statistics(markov_matrix, n_pairs: int) -> np.ndarray:\n",
    "    \"\"\"card_matching.ipynb와 동일한 분포 계산\"\"\"\n",
    "    starting_point = np.zeros(markov_matrix.shape[0])\n",
    "    starting_point[0] = 1\n",
    "\n",
    "    first_chance_to_win = markov_matrix.T ** n_pairs\n",
    "    prob_vector = first_chance_to_win @ starting_point\n",
    "    chance_to_finish_with_failures = [prob_vector[-1]]\n",
    "\n",
    "    # card_matching.ipynb와 동일한 범위\n",
    "    for number_of_failures in range(n_pairs):\n",
    "        next_prob_vector = markov_matrix.T @ prob_vector\n",
    "        chance_to_finish_with_failures.append(next_prob_vector[-1] - prob_vector[-1])\n",
    "        prob_vector = next_prob_vector\n",
    "    \n",
    "    return np.array(chance_to_finish_with_failures)\n",
    "\n",
    "def calculate_turn_penalty(skill_level: float, baseline_turns: float) -> float:\n",
    "    \"\"\"실력 수준에 따른 턴 수 증가 계산\"\"\"\n",
    "    \n",
    "    # skill_level: 1.0 (완벽) -> 0.0 (최악)\n",
    "    # 베이스라인 대비 턴 수 증가율\n",
    "    \n",
    "    if skill_level >= 0.9:\n",
    "        penalty_multiplier = 1.0  # 베이스라인 수준\n",
    "    elif skill_level >= 0.7:\n",
    "        penalty_multiplier = 1.3  # 30% 증가\n",
    "    elif skill_level >= 0.5:\n",
    "        penalty_multiplier = 1.8  # 80% 증가\n",
    "    elif skill_level >= 0.3:\n",
    "        penalty_multiplier = 2.5  # 150% 증가\n",
    "    elif skill_level >= 0.1:\n",
    "        penalty_multiplier = 3.5  # 250% 증가\n",
    "    else:\n",
    "        penalty_multiplier = 5.0  # 400% 증가\n",
    "    \n",
    "    return baseline_turns * penalty_multiplier\n",
    "\n",
    "def skill_level_to_memory_decay(skill_level: float) -> float:\n",
    "    \"\"\"실력 수준을 memory_decay_factor로 변환\"\"\"\n",
    "    # 높은 실력 = 낮은 decay, 낮은 실력 = 높은 decay\n",
    "    return max(0.0, min(0.8, (1.0 - skill_level) * 0.8))\n",
    "\n",
    "def get_user_performance_metrics(n_pairs: int, skill_level: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    실력 수준에 따른 성과 지표 계산 - 베이스라인 대비 턴 수 증가 중심\n",
    "    \"\"\"\n",
    "    # 베이스라인 계산\n",
    "    baseline_matrix = get_optimal_baseline_markov_chain(n_pairs, entire_matrix=True)\n",
    "    baseline_stats = get_case_statistics(baseline_matrix, n_pairs)\n",
    "    baseline_expected_failures = sum(i * prob for i, prob in enumerate(baseline_stats))\n",
    "    baseline_turns = baseline_expected_failures + n_pairs\n",
    "    baseline_completion_rate = sum(baseline_stats)\n",
    "    \n",
    "    # 사용자 성능 계산\n",
    "    if skill_level >= 0.95:\n",
    "        # 거의 완벽한 사용자는 베이스라인과 동일\n",
    "        user_stats = baseline_stats\n",
    "        user_expected_failures = baseline_expected_failures\n",
    "        user_completion_rate = baseline_completion_rate\n",
    "    else:\n",
    "        # 기억력 저하가 있는 사용자\n",
    "        memory_decay = skill_level_to_memory_decay(skill_level)\n",
    "        user_matrix = get_imperfect_memory_markov_chain(n_pairs, memory_decay, entire_matrix=True)\n",
    "        user_stats = get_case_statistics(user_matrix, n_pairs)\n",
    "        user_completion_rate = sum(user_stats)\n",
    "        \n",
    "        if user_completion_rate > 0:\n",
    "            user_expected_failures = sum(i * prob for i, prob in enumerate(user_stats)) / user_completion_rate\n",
    "        else:\n",
    "            user_expected_failures = float('inf')\n",
    "    \n",
    "    # 실제 턴 수 (패널티 적용)\n",
    "    actual_turns = calculate_turn_penalty(skill_level, baseline_turns)\n",
    "    \n",
    "    # 성능 지표\n",
    "    turn_increase_ratio = actual_turns / baseline_turns if baseline_turns > 0 else float('inf')\n",
    "    efficiency_score = baseline_turns / actual_turns if actual_turns > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'skill_level': skill_level,\n",
    "        'baseline_turns': baseline_turns,\n",
    "        'actual_turns': actual_turns,\n",
    "        'turn_increase_ratio': turn_increase_ratio,\n",
    "        'efficiency_score': efficiency_score,\n",
    "        'expected_failures': user_expected_failures,\n",
    "        'completion_rate': user_completion_rate,\n",
    "        'baseline_completion_rate': baseline_completion_rate\n",
    "    }\n",
    "\n",
    "def monte_carlo_user_simulation(n_pairs: int, user_skill_distribution: list, \n",
    "                               skill_levels: list = [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "                               num_simulations: int = 10000) -> dict:\n",
    "    \"\"\"유저 실력 분포를 기반으로 한 몬테카를로 시뮬레이션\"\"\"\n",
    "    \n",
    "    # 베이스라인 계산\n",
    "    baseline_matrix = get_optimal_baseline_markov_chain(n_pairs, entire_matrix=True)\n",
    "    baseline_stats = get_case_statistics(baseline_matrix, n_pairs)\n",
    "    baseline_expected_failures = sum(i * prob for i, prob in enumerate(baseline_stats))\n",
    "    baseline_turns = baseline_expected_failures + n_pairs\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for simulation in range(num_simulations):\n",
    "        # 유저 실력 샘플링\n",
    "        user_skill = np.random.choice(skill_levels, p=user_skill_distribution)\n",
    "        \n",
    "        # 해당 실력에 따른 실제 턴 수 계산\n",
    "        actual_turns = calculate_turn_penalty(user_skill, baseline_turns)\n",
    "        \n",
    "        # 게임 경제성 계산\n",
    "        ad_revenue_per_turn = 0.05  # 턴당 광고 수익\n",
    "        completion_reward = 3.0\n",
    "        \n",
    "        ad_revenue = actual_turns * ad_revenue_per_turn\n",
    "        net_profit = ad_revenue - completion_reward\n",
    "        \n",
    "        results.append({\n",
    "            'user_skill': user_skill,\n",
    "            'baseline_turns': baseline_turns,\n",
    "            'actual_turns': actual_turns,\n",
    "            'turn_increase': actual_turns - baseline_turns,\n",
    "            'turn_increase_ratio': actual_turns / baseline_turns,\n",
    "            'ad_revenue': ad_revenue,\n",
    "            'net_profit': net_profit\n",
    "        })\n",
    "    \n",
    "    # 통계 계산\n",
    "    avg_turns = np.mean([r['actual_turns'] for r in results])\n",
    "    avg_turn_increase = np.mean([r['turn_increase'] for r in results])\n",
    "    avg_profit = np.mean([r['net_profit'] for r in results])\n",
    "    \n",
    "    return {\n",
    "        'simulations': results,\n",
    "        'baseline_turns': baseline_turns,\n",
    "        'avg_actual_turns': avg_turns,\n",
    "        'avg_turn_increase': avg_turn_increase,\n",
    "        'avg_turn_increase_ratio': avg_turns / baseline_turns,\n",
    "        'avg_profit': avg_profit,\n",
    "        'total_simulations': num_simulations\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b92711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 베이스라인 vs 다양한 실력 수준 비교 ===\n",
      "실력 1.0: 베이스라인 12.39턴 → 실제 12.39턴 (+100.0%)\n",
      "실력 0.8: 베이스라인 12.39턴 → 실제 16.11턴 (+130.0%)\n",
      "실력 0.6: 베이스라인 12.39턴 → 실제 22.31턴 (+180.0%)\n",
      "실력 0.4: 베이스라인 12.39턴 → 실제 30.98턴 (+250.0%)\n",
      "실력 0.2: 베이스라인 12.39턴 → 실제 43.38턴 (+350.0%)\n",
      "실력 0.0: 베이스라인 12.39턴 → 실제 61.96턴 (+500.0%)\n",
      "\n",
      "=== 몬테카를로 시뮬레이션 ===\n",
      "베이스라인 평균 턴 수: 12.39\n",
      "실제 평균 턴 수: 32.52\n",
      "평균 턴 수 증가: +20.12턴 (+162.4%)\n",
      "평균 순이익: $-1.374\n"
     ]
    }
   ],
   "source": [
    "def example_usage():\n",
    "    \"\"\"사용 예시\"\"\"\n",
    "    n_pairs = 8\n",
    "    \n",
    "    print(\"=== 베이스라인 vs 다양한 실력 수준 비교 ===\")\n",
    "    skill_levels = [1.0, 0.8, 0.6, 0.4, 0.2, 0.0]\n",
    "    \n",
    "    for skill in skill_levels:\n",
    "        metrics = get_user_performance_metrics(n_pairs, skill)\n",
    "        print(f\"실력 {skill:.1f}: 베이스라인 {metrics['baseline_turns']:.2f}턴 → \"\n",
    "              f\"실제 {metrics['actual_turns']:.2f}턴 \"\n",
    "              f\"(+{metrics['turn_increase_ratio']:.1%})\")\n",
    "    \n",
    "    print(\"\\n=== 몬테카를로 시뮬레이션 ===\")\n",
    "    # 실제적인 유저 분포 (초보자가 많음)\n",
    "    user_distribution = [0.4, 0.3, 0.2, 0.08, 0.02]  # [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    \n",
    "    results = monte_carlo_user_simulation(\n",
    "        n_pairs=n_pairs,\n",
    "        user_skill_distribution=user_distribution,\n",
    "        num_simulations=5000\n",
    "    )\n",
    "    \n",
    "    print(f\"베이스라인 평균 턴 수: {results['baseline_turns']:.2f}\")\n",
    "    print(f\"실제 평균 턴 수: {results['avg_actual_turns']:.2f}\")\n",
    "    print(f\"평균 턴 수 증가: +{results['avg_turn_increase']:.2f}턴 \"\n",
    "          f\"(+{(results['avg_turn_increase_ratio']-1)*100:.1f}%)\")\n",
    "    print(f\"평균 순이익: ${results['avg_profit']:.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af128d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72f7a7b",
   "metadata": {},
   "source": [
    "### 시뮬\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4830363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 게임 변수\n",
    "MAX_RETRIES = 3      # 최대 재시도 횟수\n",
    "AD_REVENUE = 1.0     # 광고 수익\n",
    "\n",
    "# 게임 단계 설정\n",
    "GAME_STAGES = [\n",
    "    {'pairs': 2, 'time_limit': 5.0, 'reward': 2},    # 1단계: 2x2, 2페어\n",
    "    {'pairs': 3, 'time_limit': 7.0, 'reward': 2},    # 2단계: 2x3, 3페어  \n",
    "    {'pairs': 6, 'time_limit': 9.0, 'reward': 2},    # 3단계: 3x4, 6페어\n",
    "    {'pairs': 8, 'time_limit': 13.0, 'reward': 2},   # 4단계: 4x4, 8페어\n",
    "    {'pairs': 8, 'time_limit': 15.0, 'reward': 3},   # 5단계: 4x4, 8페어 (트릭카드)\n",
    "    {'pairs': 10, 'time_limit': 21.0, 'reward': 3},  # 6단계: 4x5, 10페어\n",
    "    {'pairs': 10, 'time_limit': 25.0, 'reward': 6}   # 7단계: 4x5, 10페어 (트릭카드)\n",
    "]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
