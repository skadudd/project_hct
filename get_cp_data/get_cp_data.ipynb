{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import datetime as dt\n",
    "import openpyxl\n",
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 폰트 경로 직접 지정\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf'  # 맑은 고딕의 경로\n",
    "font_prop = fm.FontProperties(fname=font_path, size=12)\n",
    "\n",
    "# 전역 폰트 설정\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'  # 맑은 고딕으로 설정\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호 깨짐 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = pd.read_csv('../../cp_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = keys['media'][key]\n",
    "access_key = keys['id'][key]\n",
    "secret_key = keys['secret'][key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"20240516\"\n",
    "end_date = \"20240531\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report_type = 'orders'\n",
    "report_type = 'cancels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching date ranges:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data: HTTP 504 - {\n",
      "  \"code\" : \"ERROR\",\n",
      "  \"message\" : \"Request timed out, if the situation continues consider applying timeout extension.\",\n",
      "  \"transactionId\" : \"6e2c8809-eb11-4f4e-b835-bce721f0d9f4\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching date ranges:   0%|          | 0/1 [00:10<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "import hmac\n",
    "import hashlib\n",
    "from time import gmtime, strftime\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "REQUEST_METHOD = \"GET\"\n",
    "DOMAIN = \"https://api-gateway.coupang.com\"\n",
    "URL = f\"/v2/providers/affiliate_open_api/apis/openapi/v1/reports/{report_type}\"\n",
    "\n",
    "def generateHmac(method, url, secretKey, accessKey, queryString=\"\"):\n",
    "    datetimeGMT = strftime('%y%m%d', gmtime()) + 'T' + strftime('%H%M%S', gmtime()) + 'Z'\n",
    "    message = datetimeGMT + method + url + queryString\n",
    "    signature = hmac.new(bytes(secretKey, 'utf-8'), message.encode('utf-8'), hashlib.sha256).hexdigest()\n",
    "    return f\"CEA algorithm=HmacSHA256, access-key={accessKey}, signed-date={datetimeGMT}, signature={signature}\"\n",
    "\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "def fetch_data(startDate, endDate, page, retries=3):\n",
    "    queryString = f\"startDate={startDate}&endDate={endDate}&page={page}\"\n",
    "    fullURL = f\"{DOMAIN}{URL}?{queryString}\"\n",
    "    authorization = generateHmac(REQUEST_METHOD, URL, SECRET_KEY, ACCESS_KEY, queryString)\n",
    "    headers = {\"Authorization\": authorization, \"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(fullURL, headers=headers, timeout=60)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"Failed to fetch data: HTTP {response.status_code} - {response.text}\")\n",
    "                time.sleep(2)  # Wait before retrying\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            time.sleep(2)  # Wait before retrying\n",
    "    \n",
    "    return None\n",
    "\n",
    "def fetch_data_in_chunks(start_date, end_date):\n",
    "    start = datetime.strptime(start_date, '%Y%m%d')\n",
    "    end = datetime.strptime(end_date, '%Y%m%d')\n",
    "    results = []\n",
    "\n",
    "    date_range = (end - start).days // 30 + 1  # Calculate the number of chunks\n",
    "    date_chunks = tqdm(range(date_range), desc=\"Fetching date ranges\")\n",
    "\n",
    "    for _ in date_chunks:\n",
    "        chunk_end = start + timedelta(days=29)\n",
    "        if chunk_end > end:\n",
    "            chunk_end = end\n",
    "\n",
    "        page = 0\n",
    "        while True:\n",
    "            response = fetch_data(start.strftime('%Y%m%d'), chunk_end.strftime('%Y%m%d'), page)\n",
    "            if response:\n",
    "                data = response.get('data', [])\n",
    "                if data:\n",
    "                    results.extend(data)\n",
    "                    if len(data) < 1000:\n",
    "                        break\n",
    "                    page += 1\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        start = chunk_end + timedelta(days=1)\n",
    "        if start > end:\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "# Define your access keys and date range\n",
    "ACCESS_KEY = access_key\n",
    "SECRET_KEY = secret_key\n",
    "\n",
    "\n",
    "\n",
    "# Collect all data\n",
    "all_data = fetch_data_in_chunks(start_date, end_date)\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "df['click_time'] = df['subParam'].apply(lambda x: x.split('_')[1] if isinstance(x, str) and '_' in x else None)\n",
    "df['subParam'] = df['subParam'].apply(lambda x: x.split('_')[0] if isinstance(x, str) and '_' in x else None)\n",
    "\n",
    "df['click_time'] = pd.to_datetime(df['click_time'])\n",
    "df['click_time'] = df['click_time'].dt.strftime(\"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "20240516   -6007145.0\n",
       "20240517   -6172214.0\n",
       "20240518   -4261222.0\n",
       "20240519   -8499844.0\n",
       "20240520   -6726893.0\n",
       "20240521   -4370944.0\n",
       "20240522   -5256474.0\n",
       "20240523   -4939330.0\n",
       "20240524   -3596470.0\n",
       "20240525   -3303132.0\n",
       "20240526   -4224330.0\n",
       "20240527   -5326099.0\n",
       "20240528   -5335943.0\n",
       "20240529   -4668248.0\n",
       "20240530   -5650852.0\n",
       "20240531   -5129118.0\n",
       "Name: gmv, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('date')['gmv'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if media == \"cpDynamic\":\n",
    "    if report_type == \"orders\" :\n",
    "        df.to_parquet(f'../result/cp/dynamic/orders/{media}_{report_type}_{start_date}_{end_date}.parquet')\n",
    "    else :\n",
    "        df.to_parquet(f'../result/cp/dynamic/cancels/{media}_{report_type}_{start_date}_{end_date}.parquet')\n",
    "else:\n",
    "    if report_type == \"orders\" :\n",
    "        df.to_parquet(f'../result/cp/reco/orders/{media}_{report_type}_{start_date}_{end_date}.parquet')\n",
    "    else :\n",
    "        df.to_parquet(f'../result/cp/reco/cancels/{media}_{report_type}_{start_date}_{end_date}.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
