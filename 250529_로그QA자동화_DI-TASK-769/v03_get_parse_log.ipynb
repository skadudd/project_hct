{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ë¡œê·¸ ë¶„ì„ ë° íŒŒì¼ ì¶œë ¥ ===\n",
      "JSON íŒŒì‹± ì˜¤ë¥˜ (ë¼ì¸ 94): Expecting ',' delimiter: line 1 column 618 (char 617)\n",
      "=== ì´ 385ê°œì˜ ë¡œê·¸ ë°œê²¬ ===\n",
      "\n",
      "âœ… txt íŒŒì¼ ì €ì¥: ./result/log_analysis_result.txt\n",
      "âœ… Excel íŒŒì¼ ì €ì¥: ./result/log_analysis_result.xlsx\n",
      "   ì´ 385ê°œ ë¡œê·¸ ì²˜ë¦¬ë¨\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from urllib.parse import parse_qs, urlparse, unquote\n",
    "from typing import Dict, List\n",
    "from datetime import datetime\n",
    "\n",
    "class LogAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "        self.parsed_logs = []\n",
    "\n",
    "    def parse_log_file_from_path(self, file_path: str, output_txt: str = None, output_xlsx: str = None):\n",
    "        \"\"\"\n",
    "        íŒŒì¼ ê²½ë¡œì—ì„œ ë¡œê·¸ íŒŒì¼ì„ ì½ì–´ì„œ ë¶„ì„í•˜ê³  ê²°ê³¼ ì¶œë ¥\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # ë¡œê·¸ íŒŒì‹±\n",
    "            self._parse_log_content(content)\n",
    "            \n",
    "            # txt íŒŒì¼ ì¶œë ¥\n",
    "            if output_txt:\n",
    "                self._export_to_txt(output_txt)\n",
    "            \n",
    "            # Excel íŒŒì¼ ì¶œë ¥\n",
    "            if output_xlsx:\n",
    "                self._export_to_excel(output_xlsx)\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def _parse_log_content(self, content: str):\n",
    "        \"\"\"ë¡œê·¸ ë‚´ìš© íŒŒì‹±\"\"\"\n",
    "        self.logs = []\n",
    "        self.parsed_logs = []\n",
    "        lines = content.strip().split('\\n')\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip():\n",
    "                try:\n",
    "                    log_data = json.loads(line.strip())\n",
    "                    self.logs.append((i+1, log_data))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"JSON íŒŒì‹± ì˜¤ë¥˜ (ë¼ì¸ {i+1}): {e}\")\n",
    "        \n",
    "        print(f\"=== ì´ {len(self.logs)}ê°œì˜ ë¡œê·¸ ë°œê²¬ ===\\n\")\n",
    "        \n",
    "        # ê° ë¡œê·¸ì˜ REQUEST íŒŒë¼ë¯¸í„° ë¶„ì„\n",
    "        for log_num, log_data in self.logs:\n",
    "            if 'REQUEST' in log_data:\n",
    "                params = self._parse_request_url(log_data['REQUEST'])\n",
    "                if params:\n",
    "                    parsed_log = {\n",
    "                        'log_number': log_num,\n",
    "                        'timestamp': log_data.get('LOGTIME', 'N/A'),\n",
    "                        'params': params\n",
    "                    }\n",
    "                    self.parsed_logs.append(parsed_log)\n",
    "\n",
    "    def _parse_request_url(self, request_url: str) -> Dict[str, str]:\n",
    "        \"\"\"REQUEST URLì—ì„œ íŒŒë¼ë¯¸í„°ë¥¼ íŒŒì‹±í•˜ê³  í•œê¸€ì„ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬\"\"\"\n",
    "        try:\n",
    "            # ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„ ë””ì½”ë”©\n",
    "            url = request_url.encode('utf-8').decode('unicode_escape')\n",
    "            parsed_url = urlparse(url)\n",
    "            query_params = parse_qs(parsed_url.query, keep_blank_values=True)\n",
    "            \n",
    "            processed_params = {}\n",
    "            for key, value_list in query_params.items():\n",
    "                raw_value = value_list[0] if value_list else ''\n",
    "                decoded_value = self._fix_korean_text(raw_value)\n",
    "                processed_params[key] = decoded_value\n",
    "            \n",
    "            return processed_params\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _fix_korean_text(self, text: str) -> str:\n",
    "        \"\"\"ê¹¨ì§„ í•œê¸€ì„ ì˜¬ë°”ë¥´ê²Œ ë””ì½”ë”©\"\"\"\n",
    "        try:\n",
    "            decoded = unquote(text, encoding='utf-8')\n",
    "            \n",
    "            if self._has_broken_korean(decoded):\n",
    "                try:\n",
    "                    fixed = decoded.encode('latin-1').decode('utf-8')\n",
    "                    return fixed\n",
    "                except:\n",
    "                    try:\n",
    "                        byte_data = bytes([ord(c) for c in decoded if ord(c) < 256])\n",
    "                        fixed = byte_data.decode('utf-8', errors='ignore')\n",
    "                        return fixed\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            return decoded\n",
    "            \n",
    "        except Exception:\n",
    "            return text\n",
    "\n",
    "    def _has_broken_korean(self, text: str) -> bool:\n",
    "        \"\"\"ê¹¨ì§„ í•œê¸€ íŒ¨í„´ì´ ìˆëŠ”ì§€ í™•ì¸\"\"\"\n",
    "        broken_patterns = [\n",
    "            'Ã«Â¶', 'Ã¬Ã«', 'ÃªÂ¼Â¬', 'Ã«', 'Ã­Â¼', 'Ã¬Â¸', 'ÃªÂ¸Â°', 'ÃªÂ¸', 'Ã¬Ã¬Â¹', 'Ã¬', 'Ãª'\n",
    "        ]\n",
    "        return any(pattern in text for pattern in broken_patterns)\n",
    "\n",
    "    def _export_to_txt(self, output_file: str):\n",
    "        \"\"\"íŒŒì‹± ê²°ê³¼ë¥¼ txt íŒŒì¼ë¡œ ì¶œë ¥\"\"\"\n",
    "        try:\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"=== ì´ {len(self.logs)}ê°œì˜ ë¡œê·¸ ë°œê²¬ ===\\n\\n\")\n",
    "                \n",
    "                for parsed_log in self.parsed_logs:\n",
    "                    f.write(\"=\" * 60 + \"\\n\")\n",
    "                    f.write(f\"ë¡œê·¸ #{parsed_log['log_number']} - {parsed_log['timestamp']}\\n\")\n",
    "                    f.write(\"=\" * 60 + \"\\n\")\n",
    "                    \n",
    "                    params = parsed_log['params']\n",
    "                    if params:\n",
    "                        # URL ì •ë³´ (ì²« ë²ˆì§¸ ë¡œê·¸ì—ì„œ ì¶”ì¶œ)\n",
    "                        for log_num, log_data in self.logs:\n",
    "                            if log_num == parsed_log['log_number']:\n",
    "                                if 'REQUEST' in log_data:\n",
    "                                    url = log_data['REQUEST'].encode('utf-8').decode('unicode_escape')\n",
    "                                    parsed_url = urlparse(url)\n",
    "                                    f.write(f\"URL: {parsed_url.netloc}{parsed_url.path}\\n\")\n",
    "                                    f.write(f\"ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {len(params)}\\n\")\n",
    "                                    f.write(\"-\" * 50 + \"\\n\")\n",
    "                                break\n",
    "                        \n",
    "                        # íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
    "                        for key, value in params.items():\n",
    "                            f.write(f\"{key:20} : {value}\\n\")\n",
    "                    else:\n",
    "                        f.write(\"REQUEST í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.\\n\")\n",
    "                    \n",
    "                    f.write(\"\\n\")\n",
    "            \n",
    "            print(f\"âœ… txt íŒŒì¼ ì €ì¥: {output_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ txt íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def _export_to_excel(self, output_file: str):\n",
    "        \"\"\"íŒŒì‹± ê²°ê³¼ë¥¼ Excel íŒŒì¼ë¡œ ì¶œë ¥ (page_id, click_type, act_type, click_text, key_list, value_list, len(key_list))\"\"\"\n",
    "        try:\n",
    "            excel_data = []\n",
    "            \n",
    "            for parsed_log in self.parsed_logs:\n",
    "                params = parsed_log['params']\n",
    "                \n",
    "                # ê° ë¡œê·¸ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ\n",
    "                page_id = params.get('page_id', '')\n",
    "                click_type = params.get('click_type', '')\n",
    "                act_type = params.get('act_type', '')\n",
    "                click_text = params.get('click_text', '')\n",
    "                \n",
    "                # key_listì™€ value_list ìƒì„±\n",
    "                key_list = list(params.keys())\n",
    "                value_list = list(params.values())\n",
    "                \n",
    "                key_list_str = ', '.join(key_list)\n",
    "                value_list_str = ', '.join(str(v) for v in value_list)\n",
    "                key_count = len(key_list)\n",
    "                \n",
    "                excel_data.append({\n",
    "                    'page_id': page_id,\n",
    "                    'click_type': click_type,\n",
    "                    'act_type': act_type,\n",
    "                    'click_text': click_text,\n",
    "                    'key_list': key_list_str,\n",
    "                    'value_list': value_list_str,\n",
    "                    'len(key_list)': key_count\n",
    "                })\n",
    "            \n",
    "            # DataFrame ìƒì„± ë° Excel ì €ì¥\n",
    "            df = pd.DataFrame(excel_data)\n",
    "            df.to_excel(output_file, index=False, engine='openpyxl')\n",
    "            \n",
    "            print(f\"âœ… Excel íŒŒì¼ ì €ì¥: {output_file}\")\n",
    "            print(f\"   ì´ {len(excel_data)}ê°œ ë¡œê·¸ ì²˜ë¦¬ë¨\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Excel íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def analyze_logs(self, file_path: str):\n",
    "        \"\"\"ë¡œê·¸ ë¶„ì„ (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            self._parse_log_content(content)\n",
    "            \n",
    "            # ì½˜ì†” ì¶œë ¥\n",
    "            for parsed_log in self.parsed_logs:\n",
    "                print(\"=\" * 60)\n",
    "                print(f\"ë¡œê·¸ #{parsed_log['log_number']} - {parsed_log['timestamp']}\")\n",
    "                print(\"=\" * 60)\n",
    "                \n",
    "                params = parsed_log['params']\n",
    "                if params:\n",
    "                    # URL ì •ë³´ ì¶œë ¥\n",
    "                    for log_num, log_data in self.logs:\n",
    "                        if log_num == parsed_log['log_number']:\n",
    "                            if 'REQUEST' in log_data:\n",
    "                                url = log_data['REQUEST'].encode('utf-8').decode('unicode_escape')\n",
    "                                parsed_url = urlparse(url)\n",
    "                                print(f\"URL: {parsed_url.netloc}{parsed_url.path}\")\n",
    "                                print(f\"ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {len(params)}\")\n",
    "                                print(\"-\" * 50)\n",
    "                            break\n",
    "                    \n",
    "                    # íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
    "                    for key, value in params.items():\n",
    "                        print(f\"{key:20} : {value}\")\n",
    "                else:\n",
    "                    print(\"REQUEST í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                \n",
    "                print()\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "def run_example():\n",
    "    \"\"\"ì‚¬ìš© ì˜ˆì‹œ\"\"\"\n",
    "    analyzer = LogAnalyzer()\n",
    "    \n",
    "    # 1. ë¡œê·¸ ë¶„ì„ ë° txt, Excel íŒŒì¼ ìƒì„±\n",
    "    analyzer.parse_log_file_from_path(\n",
    "        file_path=\"log_file.txt\",\n",
    "        output_txt=\"./result/log_analysis_result.txt\",\n",
    "        output_xlsx=\"./result/log_analysis_result.xlsx\"\n",
    "    )\n",
    "    \n",
    "    # 2. ì½˜ì†”ì— ë¡œê·¸ ë¶„ì„ ê²°ê³¼ ì¶œë ¥ë§Œ í•˜ê³  ì‹¶ì€ ê²½ìš°\n",
    "    # analyzer.analyze_logs(\"log_file.txt\")\n",
    "\n",
    "# ê¸°ì¡´ QA ê²€ì¦ í´ë˜ìŠ¤ (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)\n",
    "class LogQAValidator:\n",
    "    def __init__(self):\n",
    "        self.scenarios = []\n",
    "        self.logs = []\n",
    "        self.unique_keys = []\n",
    "        \n",
    "    def load_scenario_csv(self, csv_file_path: str):\n",
    "        \"\"\"CSV íŒŒì¼ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ\"\"\"\n",
    "        self.scenarios = []\n",
    "        df = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "        \n",
    "        # ì»¬ëŸ¼ êµ¬ì„±ì— ë”°ë¼ ê³ ìœ í‚¤ ì¡°í•© ê²°ì •\n",
    "        columns = df.columns.tolist()\n",
    "        if 'page_id' in columns:\n",
    "            self.unique_keys = ['page_id', 'click_type', 'act_type']\n",
    "            print(\"ğŸ”‘ ê³ ìœ í‚¤ ì¡°í•©: page_id + click_type + act_type\")\n",
    "        elif 'click_text' in columns:\n",
    "            self.unique_keys = ['click_text', 'click_type', 'act_type']\n",
    "            print(\"ğŸ”‘ ê³ ìœ í‚¤ ì¡°í•©: click_text + click_type + act_type\")\n",
    "        else:\n",
    "            raise ValueError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œë‚˜ë¦¬ì˜¤ í˜•ì‹ì…ë‹ˆë‹¤. page_id ë˜ëŠ” click_text ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            key_list = [k.strip() for k in str(row['key_list']).split(',') if k.strip()]\n",
    "            scenario = {\n",
    "                'expected_keys': key_list\n",
    "            }\n",
    "            \n",
    "            # ê³ ìœ í‚¤ ê°’ë“¤ ì¶”ê°€\n",
    "            for key in self.unique_keys:\n",
    "                scenario[key] = str(row[key]) if pd.notna(row[key]) else ''\n",
    "            \n",
    "            self.scenarios.append(scenario)\n",
    "        \n",
    "        print(f\"âœ… ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ: {len(self.scenarios)}ê°œ\")\n",
    "\n",
    "    def parse_logs_from_file(self, log_file_path: str):\n",
    "        \"\"\"ë¡œê·¸ txt íŒŒì¼ì—ì„œ ì§ì ‘ íŒŒì‹±\"\"\"\n",
    "        try:\n",
    "            with open(log_file_path, 'r', encoding='utf-8') as file:\n",
    "                log_content = file.read()\n",
    "            self.parse_logs(log_content)\n",
    "            print(f\"âœ… ë¡œê·¸ íŒŒì¼ ë¡œë“œ: {log_file_path}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def parse_logs(self, log_content: str):\n",
    "        \"\"\"ë¡œê·¸ íŒŒì‹±\"\"\"\n",
    "        self.logs = []\n",
    "        for i, line in enumerate(log_content.strip().split('\\n')):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                log_data = json.loads(line.strip())\n",
    "                if 'REQUEST' not in log_data:\n",
    "                    continue\n",
    "                    \n",
    "                params = self._parse_url(log_data['REQUEST'])\n",
    "                if params:\n",
    "                    self.logs.append({\n",
    "                        'line': i + 1,\n",
    "                        'timestamp': log_data.get('LOGTIME', ''),\n",
    "                        'params': params\n",
    "                    })\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "                \n",
    "        print(f\"âœ… ë¡œê·¸ íŒŒì‹±: {len(self.logs)}ê°œ\")\n",
    "\n",
    "    def _parse_url(self, request_url: str) -> Dict[str, str]:\n",
    "        \"\"\"URL íŒŒë¼ë¯¸í„° íŒŒì‹±\"\"\"\n",
    "        try:\n",
    "            url = request_url.encode('utf-8').decode('unicode_escape')\n",
    "            parsed = urlparse(url)\n",
    "            query_params = parse_qs(parsed.query, keep_blank_values=True)\n",
    "            \n",
    "            result = {}\n",
    "            for key, values in query_params.items():\n",
    "                if values:\n",
    "                    decoded = unquote(values[0], encoding='utf-8')\n",
    "                    # í•œê¸€ ê¹¨ì§ ë³µêµ¬ ì‹œë„\n",
    "                    try:\n",
    "                        if any(ord(c) > 127 for c in decoded):\n",
    "                            decoded = decoded.encode('latin-1').decode('utf-8')\n",
    "                    except:\n",
    "                        pass\n",
    "                    result[key] = decoded\n",
    "            return result\n",
    "        except:\n",
    "            return {}\n",
    "\n",
    "    def validate_and_export(self, output_file: str):\n",
    "        \"\"\"ê²€ì¦ ìˆ˜í–‰ ë° ê²°ê³¼ XLSX ì¶œë ¥\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for scenario in self.scenarios:\n",
    "            # ì‹œë‚˜ë¦¬ì˜¤ì™€ ë§¤ì¹­ë˜ëŠ” ë¡œê·¸ ì°¾ê¸°\n",
    "            matched_logs = self._find_matching_logs(scenario)\n",
    "            \n",
    "            if not matched_logs:\n",
    "                # ë§¤ì¹­ë˜ëŠ” ë¡œê·¸ê°€ ì—†ëŠ” ê²½ìš°\n",
    "                for key in scenario['expected_keys']:\n",
    "                    result = {\n",
    "                        'key': key,\n",
    "                        'value': 'NOT_FOUND',\n",
    "                        'pass': 'FAIL'\n",
    "                    }\n",
    "                    \n",
    "                    # ê³ ìœ í‚¤ ê°’ë“¤ ì¶”ê°€\n",
    "                    for uk in self.unique_keys:\n",
    "                        result[uk] = scenario.get(uk, '')\n",
    "                    \n",
    "                    results.append(result)\n",
    "                continue\n",
    "            \n",
    "            # ê° ë§¤ì¹­ëœ ë¡œê·¸ì— ëŒ€í•´ ê²€ì¦\n",
    "            for log in matched_logs:\n",
    "                actual_keys = set(log['params'].keys())\n",
    "                expected_keys = set(scenario['expected_keys'])\n",
    "                \n",
    "                # ì˜ˆìƒ í‚¤ë“¤ ê²€ì¦\n",
    "                for key in expected_keys:\n",
    "                    value = log['params'].get(key, 'MISSING')\n",
    "                    pass_status = 'PASS' if key in actual_keys else 'FAIL'\n",
    "                    \n",
    "                    result = {\n",
    "                        'key': key,\n",
    "                        'value': value,\n",
    "                        'pass': pass_status\n",
    "                    }\n",
    "                    \n",
    "                    # ê³ ìœ í‚¤ ê°’ë“¤ ì¶”ê°€\n",
    "                    for uk in self.unique_keys:\n",
    "                        result[uk] = scenario.get(uk, '')\n",
    "                    \n",
    "                    results.append(result)\n",
    "                \n",
    "                # ì˜ˆìƒì¹˜ ëª»í•œ í‚¤ë“¤ (ì„ íƒì‚¬í•­)\n",
    "                unexpected_keys = actual_keys - expected_keys\n",
    "                for key in unexpected_keys:\n",
    "                    result = {\n",
    "                        'key': key,\n",
    "                        'value': log['params'][key],\n",
    "                        'pass': 'UNEXPECTED'\n",
    "                    }\n",
    "                    \n",
    "                    # ê³ ìœ í‚¤ ê°’ë“¤ ì¶”ê°€\n",
    "                    for uk in self.unique_keys:\n",
    "                        result[uk] = scenario.get(uk, '')\n",
    "                    \n",
    "                    results.append(result)\n",
    "\n",
    "        # XLSX ì¶œë ¥ - ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬\n",
    "        df_results = pd.DataFrame(results)\n",
    "        \n",
    "        # ê³ ìœ í‚¤ ì¡°í•©ì— ë”°ë¥¸ ì»¬ëŸ¼ ìˆœì„œ ì •ì˜\n",
    "        if 'page_id' in self.unique_keys:\n",
    "            column_order = ['page_id', 'click_type', 'act_type', 'key', 'value', 'pass']\n",
    "        else:  # click_text ê¸°ë°˜\n",
    "            column_order = ['click_text', 'click_type', 'act_type', 'key', 'value', 'pass']\n",
    "        \n",
    "        # ì»¬ëŸ¼ ìˆœì„œ ì ìš©\n",
    "        df_results = df_results[column_order]\n",
    "        df_results.to_excel(output_file, index=False, engine='openpyxl')\n",
    "        \n",
    "        # ìš”ì•½ ì¶œë ¥\n",
    "        self._print_summary(results)\n",
    "        print(f\"âœ… ê²°ê³¼ ì €ì¥: {output_file}\")\n",
    "\n",
    "    def _find_matching_logs(self, scenario: Dict) -> List[Dict]:\n",
    "        \"\"\"ì‹œë‚˜ë¦¬ì˜¤ì™€ ë§¤ì¹­ë˜ëŠ” ë¡œê·¸ ì°¾ê¸°\"\"\"\n",
    "        matched = []\n",
    "        \n",
    "        for log in self.logs:\n",
    "            params = log['params']\n",
    "            \n",
    "            # ë™ì  ê³ ìœ í‚¤ë¡œ ë§¤ì¹­\n",
    "            is_match = True\n",
    "            for key in self.unique_keys:\n",
    "                if params.get(key, '') != scenario.get(key, ''):\n",
    "                    is_match = False\n",
    "                    break\n",
    "            \n",
    "            if is_match:\n",
    "                matched.append(log)\n",
    "        \n",
    "        return matched\n",
    "\n",
    "    def _print_summary(self, results: List[Dict]):\n",
    "        \"\"\"ê²°ê³¼ ìš”ì•½ ì¶œë ¥\"\"\"\n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        total = len(df)\n",
    "        passed = len(df[df['pass'] == 'PASS'])\n",
    "        failed = len(df[df['pass'] == 'FAIL'])\n",
    "        unexpected = len(df[df['pass'] == 'UNEXPECTED'])\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ê²€ì¦ ê²°ê³¼:\")\n",
    "        print(f\"   ì „ì²´: {total}ê°œ\")\n",
    "        print(f\"   í†µê³¼: {passed}ê°œ\")\n",
    "        print(f\"   ì‹¤íŒ¨: {failed}ê°œ\")\n",
    "        print(f\"   ì˜ˆìƒì™¸: {unexpected}ê°œ\")\n",
    "        print(f\"   ì„±ê³µë¥ : {passed/total*100:.1f}%\" if total > 0 else \"   ì„±ê³µë¥ : 0%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ë¡œê·¸ ë¶„ì„ ë° íŒŒì¼ ì¶œë ¥ ì˜ˆì‹œ\n",
    "    print(\"=== ë¡œê·¸ ë¶„ì„ ë° íŒŒì¼ ì¶œë ¥ ===\")\n",
    "    run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
