{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ CSV ìƒì„±: scenario.csv\n",
      "âœ… ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ: 4ê°œ\n",
      "âœ… ë¡œê·¸ íŒŒì‹±: 4ê°œ\n",
      "âœ… ë¡œê·¸ íŒŒì¼ ë¡œë“œ: log_file.txt\n",
      "\n",
      "ğŸ“Š ê²€ì¦ ê²°ê³¼:\n",
      "   ì „ì²´: 19ê°œ\n",
      "   í†µê³¼: 19ê°œ\n",
      "   ì‹¤íŒ¨: 0ê°œ\n",
      "   ì˜ˆìƒì™¸: 0ê°œ\n",
      "   ì„±ê³µë¥ : 100.0%\n",
      "âœ… ê²°ê³¼ ì €ì¥: validation_result.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from urllib.parse import parse_qs, urlparse, unquote\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class LogQAValidator:\n",
    "    def __init__(self):\n",
    "        self.scenarios = []\n",
    "        self.logs = []\n",
    "        \n",
    "    def load_scenario_csv(self, csv_file_path: str):\n",
    "        \"\"\"CSV íŒŒì¼ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ\"\"\"\n",
    "        self.scenarios = []\n",
    "        df = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            key_list = [k.strip() for k in str(row['key_list']).split(',') if k.strip()]\n",
    "            scenario = {\n",
    "                'page_id': str(row['page_id']),\n",
    "                'click_type': str(row['click_type']) if pd.notna(row['click_type']) else '',\n",
    "                'act_type': str(row['act_type']),\n",
    "                'expected_keys': key_list\n",
    "            }\n",
    "            self.scenarios.append(scenario)\n",
    "        \n",
    "        print(f\"âœ… ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ: {len(self.scenarios)}ê°œ\")\n",
    "\n",
    "    def parse_logs_from_file(self, log_file_path: str):\n",
    "        \"\"\"ë¡œê·¸ txt íŒŒì¼ì—ì„œ ì§ì ‘ íŒŒì‹±\"\"\"\n",
    "        try:\n",
    "            with open(log_file_path, 'r', encoding='utf-8') as file:\n",
    "                log_content = file.read()\n",
    "            self.parse_logs(log_content)\n",
    "            print(f\"âœ… ë¡œê·¸ íŒŒì¼ ë¡œë“œ: {log_file_path}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def parse_logs(self, log_content: str):\n",
    "        \"\"\"ë¡œê·¸ íŒŒì‹±\"\"\"\n",
    "        self.logs = []\n",
    "        for i, line in enumerate(log_content.strip().split('\\n')):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                log_data = json.loads(line.strip())\n",
    "                if 'REQUEST' not in log_data:\n",
    "                    continue\n",
    "                    \n",
    "                params = self._parse_url(log_data['REQUEST'])\n",
    "                if params:\n",
    "                    self.logs.append({\n",
    "                        'line': i + 1,\n",
    "                        'timestamp': log_data.get('LOGTIME', ''),\n",
    "                        'params': params\n",
    "                    })\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "                \n",
    "        print(f\"âœ… ë¡œê·¸ íŒŒì‹±: {len(self.logs)}ê°œ\")\n",
    "\n",
    "    def _parse_url(self, request_url: str) -> Dict[str, str]:\n",
    "        \"\"\"URL íŒŒë¼ë¯¸í„° íŒŒì‹±\"\"\"\n",
    "        try:\n",
    "            url = request_url.encode('utf-8').decode('unicode_escape')\n",
    "            parsed = urlparse(url)\n",
    "            query_params = parse_qs(parsed.query, keep_blank_values=True)\n",
    "            \n",
    "            result = {}\n",
    "            for key, values in query_params.items():\n",
    "                if values:\n",
    "                    decoded = unquote(values[0], encoding='utf-8')\n",
    "                    # í•œê¸€ ê¹¨ì§ ë³µêµ¬ ì‹œë„\n",
    "                    try:\n",
    "                        if any(ord(c) > 127 for c in decoded):\n",
    "                            decoded = decoded.encode('latin-1').decode('utf-8')\n",
    "                    except:\n",
    "                        pass\n",
    "                    result[key] = decoded\n",
    "            return result\n",
    "        except:\n",
    "            return {}\n",
    "\n",
    "    def validate_and_export(self, output_file: str):\n",
    "        \"\"\"ê²€ì¦ ìˆ˜í–‰ ë° ê²°ê³¼ XLSX ì¶œë ¥\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for scenario in self.scenarios:\n",
    "            # ì‹œë‚˜ë¦¬ì˜¤ì™€ ë§¤ì¹­ë˜ëŠ” ë¡œê·¸ ì°¾ê¸°\n",
    "            matched_logs = self._find_matching_logs(scenario)\n",
    "            \n",
    "            if not matched_logs:\n",
    "                # ë§¤ì¹­ë˜ëŠ” ë¡œê·¸ê°€ ì—†ëŠ” ê²½ìš°\n",
    "                for key in scenario['expected_keys']:\n",
    "                    results.append({\n",
    "                        'page_id': scenario['page_id'],\n",
    "                        'click_type': scenario['click_type'],\n",
    "                        'act_type': scenario['act_type'],\n",
    "                        'key': key,\n",
    "                        'value': 'NOT_FOUND',\n",
    "                        'pass': 'FAIL'\n",
    "                    })\n",
    "                continue\n",
    "            \n",
    "            # ê° ë§¤ì¹­ëœ ë¡œê·¸ì— ëŒ€í•´ ê²€ì¦\n",
    "            for log in matched_logs:\n",
    "                actual_keys = set(log['params'].keys())\n",
    "                expected_keys = set(scenario['expected_keys'])\n",
    "                \n",
    "                # ì˜ˆìƒ í‚¤ë“¤ ê²€ì¦\n",
    "                for key in expected_keys:\n",
    "                    value = log['params'].get(key, 'MISSING')\n",
    "                    pass_status = 'PASS' if key in actual_keys else 'FAIL'\n",
    "                    \n",
    "                    results.append({\n",
    "                        'page_id': scenario['page_id'],\n",
    "                        'click_type': scenario['click_type'],\n",
    "                        'act_type': scenario['act_type'],\n",
    "                        'key': key,\n",
    "                        'value': value,\n",
    "                        'pass': pass_status\n",
    "                    })\n",
    "                \n",
    "                # ì˜ˆìƒì¹˜ ëª»í•œ í‚¤ë“¤ (ì„ íƒì‚¬í•­)\n",
    "                unexpected_keys = actual_keys - expected_keys\n",
    "                for key in unexpected_keys:\n",
    "                    results.append({\n",
    "                        'page_id': scenario['page_id'],\n",
    "                        'click_type': scenario['click_type'],\n",
    "                        'act_type': scenario['act_type'],\n",
    "                        'key': key,\n",
    "                        'value': log['params'][key],\n",
    "                        'pass': 'UNEXPECTED'\n",
    "                    })\n",
    "\n",
    "        # XLSX ì¶œë ¥\n",
    "        df_results = pd.DataFrame(results)\n",
    "        df_results.to_excel(output_file, index=False, engine='openpyxl')\n",
    "        \n",
    "        # ìš”ì•½ ì¶œë ¥\n",
    "        self._print_summary(results)\n",
    "        print(f\"âœ… ê²°ê³¼ ì €ì¥: {output_file}\")\n",
    "\n",
    "    def _find_matching_logs(self, scenario: Dict) -> List[Dict]:\n",
    "        \"\"\"ì‹œë‚˜ë¦¬ì˜¤ì™€ ë§¤ì¹­ë˜ëŠ” ë¡œê·¸ ì°¾ê¸°\"\"\"\n",
    "        matched = []\n",
    "        \n",
    "        for log in self.logs:\n",
    "            params = log['params']\n",
    "            \n",
    "            # unique idë¡œ ë§¤ì¹­\n",
    "            if (params.get('page_id') == scenario['page_id'] and\n",
    "                params.get('click_type', '') == scenario['click_type'] and\n",
    "                params.get('act_type') == scenario['act_type']):\n",
    "                matched.append(log)\n",
    "        \n",
    "        return matched\n",
    "\n",
    "    def _print_summary(self, results: List[Dict]):\n",
    "        \"\"\"ê²°ê³¼ ìš”ì•½ ì¶œë ¥\"\"\"\n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        total = len(df)\n",
    "        passed = len(df[df['pass'] == 'PASS'])\n",
    "        failed = len(df[df['pass'] == 'FAIL'])\n",
    "        unexpected = len(df[df['pass'] == 'UNEXPECTED'])\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ê²€ì¦ ê²°ê³¼:\")\n",
    "        print(f\"   ì „ì²´: {total}ê°œ\")\n",
    "        print(f\"   í†µê³¼: {passed}ê°œ\")\n",
    "        print(f\"   ì‹¤íŒ¨: {failed}ê°œ\")\n",
    "        print(f\"   ì˜ˆìƒì™¸: {unexpected}ê°œ\")\n",
    "        print(f\"   ì„±ê³µë¥ : {passed/total*100:.1f}%\" if total > 0 else \"   ì„±ê³µë¥ : 0%\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "def create_sample_scenario_csv():\n",
    "    \"\"\"ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ CSV ìƒì„±\"\"\"\n",
    "    sample_data = [\n",
    "        {\n",
    "            'page_id': 'life-dev/main',\n",
    "            'click_type': '',\n",
    "            'act_type': 'impression',\n",
    "            'key_list': 'channel, page_url, page_id, act_type, banner_text'\n",
    "        },\n",
    "        {\n",
    "            'page_id': 'life-dev/main',\n",
    "            'click_type': '',\n",
    "            'act_type': 'pageview',\n",
    "            'key_list': 'channel, page_url, page_id, act_type'\n",
    "        },\n",
    "        {\n",
    "            'page_id': 'life-dev/myPage',\n",
    "            'click_type': '',\n",
    "            'act_type': 'pageview',\n",
    "            'key_list': 'channel, page_url, page_id, act_type'\n",
    "        },\n",
    "        {\n",
    "            'page_id': 'life-dev/main',\n",
    "            'click_type': 'í€µë²„íŠ¼',\n",
    "            'act_type': 'click',\n",
    "            'key_list': 'channel, page_url, page_id, act_type, click_text, click_type'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    df.to_csv('scenario.csv', index=False, encoding='utf-8')\n",
    "    print(\"âœ… ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ CSV ìƒì„±: scenario.csv\")\n",
    "\n",
    "def run_example():\n",
    "    \"\"\"ì‹¤í–‰ ì˜ˆì‹œ\"\"\"\n",
    "    # ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ CSV ìƒì„±\n",
    "    create_sample_scenario_csv()\n",
    "    \n",
    "    # ê²€ì¦ê¸° ì´ˆê¸°í™”\n",
    "    validator = LogQAValidator()\n",
    "    \n",
    "    # ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ\n",
    "    validator.load_scenario_csv('scenario.csv')\n",
    "    \n",
    "    # ë¡œê·¸ íŒŒì¼ì—ì„œ ì§ì ‘ íŒŒì‹±\n",
    "    validator.parse_logs_from_file('log_file.txt')\n",
    "    \n",
    "    # ë˜ëŠ” ë¬¸ìì—´ë¡œ íŒŒì‹± (ì˜ˆì‹œìš©)\n",
    "#     log_data = '''\n",
    "# {\"REQUEST\":\"https://life-dev.hectoinnovation.co.kr/main?channel\\\\u003dRround\\\\u0026page_url\\\\u003dhttps://life-dev.hectoinnovation.co.kr/main\\\\u0026page_id\\\\u003dlife-dev/main\\\\u0026act_type\\\\u003dimpression\\\\u0026banner_text\\\\u003dì• êµ­ê°€\"}\n",
    "# {\"REQUEST\":\"https://life-dev.hectoinnovation.co.kr/main?channel\\\\u003dRround\\\\u0026page_url\\\\u003dhttps://life-dev.hectoinnovation.co.kr/main\\\\u0026page_id\\\\u003dlife-dev/main\\\\u0026act_type\\\\u003dpageview\"}\n",
    "# {\"REQUEST\":\"https://life-dev.hectoinnovation.co.kr/myPage?channel\\\\u003dRround\\\\u0026page_url\\\\u003dhttps://life-dev.hectoinnovation.co.kr/myPage\\\\u0026page_id\\\\u003dlife-dev/myPage\\\\u0026act_type\\\\u003dpageview\"}\n",
    "# {\"REQUEST\":\"https://life-dev.hectoinnovation.co.kr/main?channel\\\\u003dRround\\\\u0026page_url\\\\u003dhttps://life-dev.hectoinnovation.co.kr/main\\\\u0026page_id\\\\u003dlife-dev/main\\\\u0026act_type\\\\u003dclick\\\\u0026click_text\\\\u003dë¼ìš´ë“œë¡œë˜\\\\u0026click_type\\\\u003dí€µë²„íŠ¼\"}\n",
    "# '''\n",
    "    # validator.parse_logs(log_data)\n",
    "    \n",
    "    # ê²€ì¦ ë° ê²°ê³¼ ì¶œë ¥\n",
    "    validator.validate_and_export('validation_result.xlsx')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ CSV ìƒì„±: scenario.csv\n",
      "âœ… ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ: 4ê°œ\n",
      "âœ… ë¡œê·¸ íŒŒì‹±: 4ê°œ\n",
      "âœ… ë¡œê·¸ íŒŒì¼ ë¡œë“œ: log_file.txt\n",
      "\n",
      "ğŸ“Š ê²€ì¦ ê²°ê³¼:\n",
      "   ì „ì²´: 19ê°œ\n",
      "   í†µê³¼: 13ê°œ\n",
      "   ì‹¤íŒ¨: 6ê°œ\n",
      "   ì˜ˆìƒì™¸: 0ê°œ\n",
      "   ì„±ê³µë¥ : 68.4%\n",
      "âœ… ê²°ê³¼ ì €ì¥: validation_result.xlsx\n"
     ]
    }
   ],
   "source": [
    "def run_test():\n",
    "    \"\"\"ì‹¤í–‰ ì˜ˆì‹œ\"\"\"\n",
    "    # ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ CSV ìƒì„±\n",
    "    create_sample_scenario_csv()\n",
    "    \n",
    "    # ê²€ì¦ê¸° ì´ˆê¸°í™”\n",
    "    validator = LogQAValidator()\n",
    "    \n",
    "    # ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ\n",
    "    validator.load_scenario_csv('scenario.csv')\n",
    "    \n",
    "    # ë¡œê·¸ íŒŒì¼ì—ì„œ ì§ì ‘ íŒŒì‹±\n",
    "    validator.parse_logs_from_file('log_file.txt')\n",
    "    \n",
    "    # ê²€ì¦ ë° ê²°ê³¼ ì¶œë ¥\n",
    "    validator.validate_and_export('validation_result.xlsx')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
