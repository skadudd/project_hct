{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ CSV ìƒì„±:\n",
      "   - scenario_case1.csv (page_id ê¸°ë°˜)\n",
      "   - scenario_case2.csv (click_text ê¸°ë°˜)\n",
      "\n",
      "=== Case 1: page_id ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ===\n",
      "ğŸ”‘ ê³ ìœ í‚¤ ì¡°í•©: page_id + click_type + act_type\n",
      "âœ… ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ: 3ê°œ\n",
      "âœ… ë¡œê·¸ íŒŒì‹±: 3ê°œ\n",
      "\n",
      "ğŸ“Š ê²€ì¦ ê²°ê³¼:\n",
      "   ì „ì²´: 15ê°œ\n",
      "   í†µê³¼: 15ê°œ\n",
      "   ì‹¤íŒ¨: 0ê°œ\n",
      "   ì˜ˆìƒì™¸: 0ê°œ\n",
      "   ì„±ê³µë¥ : 100.0%\n",
      "âœ… ê²°ê³¼ ì €ì¥: ./result/validation_result_case1.xlsx\n",
      "\n",
      "=== Case 2: click_text ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ===\n",
      "ğŸ”‘ ê³ ìœ í‚¤ ì¡°í•©: click_text + click_type + act_type\n",
      "âœ… ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ: 2ê°œ\n",
      "âœ… ë¡œê·¸ íŒŒì‹±: 2ê°œ\n",
      "\n",
      "ğŸ“Š ê²€ì¦ ê²°ê³¼:\n",
      "   ì „ì²´: 10ê°œ\n",
      "   í†µê³¼: 10ê°œ\n",
      "   ì‹¤íŒ¨: 0ê°œ\n",
      "   ì˜ˆìƒì™¸: 0ê°œ\n",
      "   ì„±ê³µë¥ : 100.0%\n",
      "âœ… ê²°ê³¼ ì €ì¥: ./result/validation_result_case2.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from urllib.parse import parse_qs, urlparse, unquote\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class LogQAValidator:\n",
    "    def __init__(self):\n",
    "        self.scenarios = []\n",
    "        self.logs = []\n",
    "        \n",
    "    def load_scenario_csv(self, csv_file_path: str):\n",
    "        \"\"\"CSV íŒŒì¼ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ\"\"\"\n",
    "        self.scenarios = []\n",
    "        df = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "        \n",
    "        # ì»¬ëŸ¼ êµ¬ì„±ì— ë”°ë¼ ê³ ìœ í‚¤ ì¡°í•© ê²°ì •\n",
    "        columns = df.columns.tolist()\n",
    "        if 'page_id' in columns:\n",
    "            self.unique_keys = ['page_id', 'click_type', 'act_type']\n",
    "            print(\"ğŸ”‘ ê³ ìœ í‚¤ ì¡°í•©: page_id + click_type + act_type\")\n",
    "        elif 'click_text' in columns:\n",
    "            self.unique_keys = ['click_text', 'click_type', 'act_type']\n",
    "            print(\"ğŸ”‘ ê³ ìœ í‚¤ ì¡°í•©: click_text + click_type + act_type\")\n",
    "        else:\n",
    "            raise ValueError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œë‚˜ë¦¬ì˜¤ í˜•ì‹ì…ë‹ˆë‹¤. page_id ë˜ëŠ” click_text ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            key_list = [k.strip() for k in str(row['key_list']).split(',') if k.strip()]\n",
    "            scenario = {\n",
    "                'expected_keys': key_list\n",
    "            }\n",
    "            \n",
    "            # ê³ ìœ í‚¤ ê°’ë“¤ ì¶”ê°€\n",
    "            for key in self.unique_keys:\n",
    "                scenario[key] = str(row[key]) if pd.notna(row[key]) else ''\n",
    "            \n",
    "            self.scenarios.append(scenario)\n",
    "        \n",
    "        print(f\"âœ… ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ: {len(self.scenarios)}ê°œ\")\n",
    "\n",
    "    def parse_logs_from_file(self, log_file_path: str):\n",
    "        \"\"\"ë¡œê·¸ txt íŒŒì¼ì—ì„œ ì§ì ‘ íŒŒì‹±\"\"\"\n",
    "        try:\n",
    "            with open(log_file_path, 'r', encoding='utf-8') as file:\n",
    "                log_content = file.read()\n",
    "            self.parse_logs(log_content)\n",
    "            print(f\"âœ… ë¡œê·¸ íŒŒì¼ ë¡œë“œ: {log_file_path}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def parse_logs(self, log_content: str):\n",
    "        \"\"\"ë¡œê·¸ íŒŒì‹±\"\"\"\n",
    "        self.logs = []\n",
    "        for i, line in enumerate(log_content.strip().split('\\n')):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                log_data = json.loads(line.strip())\n",
    "                if 'REQUEST' not in log_data:\n",
    "                    continue\n",
    "                    \n",
    "                params = self._parse_url(log_data['REQUEST'])\n",
    "                if params:\n",
    "                    self.logs.append({\n",
    "                        'line': i + 1,\n",
    "                        'timestamp': log_data.get('LOGTIME', ''),\n",
    "                        'params': params\n",
    "                    })\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "                \n",
    "        print(f\"âœ… ë¡œê·¸ íŒŒì‹±: {len(self.logs)}ê°œ\")\n",
    "\n",
    "    def _parse_url(self, request_url: str) -> Dict[str, str]:\n",
    "        \"\"\"URL íŒŒë¼ë¯¸í„° íŒŒì‹±\"\"\"\n",
    "        try:\n",
    "            url = request_url.encode('utf-8').decode('unicode_escape')\n",
    "            parsed = urlparse(url)\n",
    "            query_params = parse_qs(parsed.query, keep_blank_values=True)\n",
    "            \n",
    "            result = {}\n",
    "            for key, values in query_params.items():\n",
    "                if values:\n",
    "                    decoded = unquote(values[0], encoding='utf-8')\n",
    "                    # í•œê¸€ ê¹¨ì§ ë³µêµ¬ ì‹œë„\n",
    "                    try:\n",
    "                        if any(ord(c) > 127 for c in decoded):\n",
    "                            decoded = decoded.encode('latin-1').decode('utf-8')\n",
    "                    except:\n",
    "                        pass\n",
    "                    result[key] = decoded\n",
    "            return result\n",
    "        except:\n",
    "            return {}\n",
    "\n",
    "    def validate_and_export(self, output_file: str):\n",
    "        \"\"\"ê²€ì¦ ìˆ˜í–‰ ë° ê²°ê³¼ XLSX ì¶œë ¥\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for scenario in self.scenarios:\n",
    "            # ì‹œë‚˜ë¦¬ì˜¤ì™€ ë§¤ì¹­ë˜ëŠ” ë¡œê·¸ ì°¾ê¸°\n",
    "            matched_logs = self._find_matching_logs(scenario)\n",
    "            \n",
    "            if not matched_logs:\n",
    "                # ë§¤ì¹­ë˜ëŠ” ë¡œê·¸ê°€ ì—†ëŠ” ê²½ìš°\n",
    "                for key in scenario['expected_keys']:\n",
    "                    result = {\n",
    "                        'key': key,\n",
    "                        'value': 'NOT_FOUND',\n",
    "                        'pass': 'FAIL'\n",
    "                    }\n",
    "                    \n",
    "                    # ê³ ìœ í‚¤ ê°’ë“¤ ì¶”ê°€\n",
    "                    for uk in self.unique_keys:\n",
    "                        result[uk] = scenario.get(uk, '')\n",
    "                    \n",
    "                    results.append(result)\n",
    "                continue\n",
    "            \n",
    "            # ê° ë§¤ì¹­ëœ ë¡œê·¸ì— ëŒ€í•´ ê²€ì¦\n",
    "            for log in matched_logs:\n",
    "                actual_keys = set(log['params'].keys())\n",
    "                expected_keys = set(scenario['expected_keys'])\n",
    "                \n",
    "                # ì˜ˆìƒ í‚¤ë“¤ ê²€ì¦\n",
    "                for key in expected_keys:\n",
    "                    value = log['params'].get(key, 'MISSING')\n",
    "                    pass_status = 'PASS' if key in actual_keys else 'FAIL'\n",
    "                    \n",
    "                    result = {\n",
    "                        'key': key,\n",
    "                        'value': value,\n",
    "                        'pass': pass_status\n",
    "                    }\n",
    "                    \n",
    "                    # ê³ ìœ í‚¤ ê°’ë“¤ ì¶”ê°€\n",
    "                    for uk in self.unique_keys:\n",
    "                        result[uk] = scenario.get(uk, '')\n",
    "                    \n",
    "                    results.append(result)\n",
    "                \n",
    "                # ì˜ˆìƒì¹˜ ëª»í•œ í‚¤ë“¤ (ì„ íƒì‚¬í•­)\n",
    "                unexpected_keys = actual_keys - expected_keys\n",
    "                for key in unexpected_keys:\n",
    "                    result = {\n",
    "                        'key': key,\n",
    "                        'value': log['params'][key],\n",
    "                        'pass': 'UNEXPECTED'\n",
    "                    }\n",
    "                    \n",
    "                    # ê³ ìœ í‚¤ ê°’ë“¤ ì¶”ê°€\n",
    "                    for uk in self.unique_keys:\n",
    "                        result[uk] = scenario.get(uk, '')\n",
    "                    \n",
    "                    results.append(result)\n",
    "\n",
    "        # XLSX ì¶œë ¥ - ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬\n",
    "        df_results = pd.DataFrame(results)\n",
    "        \n",
    "        # ê³ ìœ í‚¤ ì¡°í•©ì— ë”°ë¥¸ ì»¬ëŸ¼ ìˆœì„œ ì •ì˜\n",
    "        if 'page_id' in self.unique_keys:\n",
    "            column_order = ['page_id', 'click_type', 'act_type', 'key', 'value', 'pass']\n",
    "        else:  # click_text ê¸°ë°˜\n",
    "            column_order = ['click_text', 'click_type', 'act_type', 'key', 'value', 'pass']\n",
    "        \n",
    "        # ì»¬ëŸ¼ ìˆœì„œ ì ìš©\n",
    "        df_results = df_results[column_order]\n",
    "        df_results.to_excel(output_file, index=False, engine='openpyxl')\n",
    "        \n",
    "        # ìš”ì•½ ì¶œë ¥\n",
    "        self._print_summary(results)\n",
    "        print(f\"âœ… ê²°ê³¼ ì €ì¥: {output_file}\")\n",
    "\n",
    "    def _find_matching_logs(self, scenario: Dict) -> List[Dict]:\n",
    "        \"\"\"ì‹œë‚˜ë¦¬ì˜¤ì™€ ë§¤ì¹­ë˜ëŠ” ë¡œê·¸ ì°¾ê¸°\"\"\"\n",
    "        matched = []\n",
    "        \n",
    "        for log in self.logs:\n",
    "            params = log['params']\n",
    "            \n",
    "            # ë™ì  ê³ ìœ í‚¤ë¡œ ë§¤ì¹­\n",
    "            is_match = True\n",
    "            for key in self.unique_keys:\n",
    "                if params.get(key, '') != scenario.get(key, ''):\n",
    "                    is_match = False\n",
    "                    break\n",
    "            \n",
    "            if is_match:\n",
    "                matched.append(log)\n",
    "        \n",
    "        return matched\n",
    "\n",
    "    def _print_summary(self, results: List[Dict]):\n",
    "        \"\"\"ê²°ê³¼ ìš”ì•½ ì¶œë ¥\"\"\"\n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        total = len(df)\n",
    "        passed = len(df[df['pass'] == 'PASS'])\n",
    "        failed = len(df[df['pass'] == 'FAIL'])\n",
    "        unexpected = len(df[df['pass'] == 'UNEXPECTED'])\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ê²€ì¦ ê²°ê³¼:\")\n",
    "        print(f\"   ì „ì²´: {total}ê°œ\")\n",
    "        print(f\"   í†µê³¼: {passed}ê°œ\")\n",
    "        print(f\"   ì‹¤íŒ¨: {failed}ê°œ\")\n",
    "        print(f\"   ì˜ˆìƒì™¸: {unexpected}ê°œ\")\n",
    "        print(f\"   ì„±ê³µë¥ : {passed/total*100:.1f}%\" if total > 0 else \"   ì„±ê³µë¥ : 0%\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "def create_sample_scenario_csv():\n",
    "    \"\"\"ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ CSV ìƒì„±\"\"\"\n",
    "    # Case 1: page_id ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤\n",
    "    sample_data_case1 = [\n",
    "        {\n",
    "            'page_id': 'life-dev/main',\n",
    "            'click_type': '',\n",
    "            'act_type': 'impression',\n",
    "            'key_list': 'channel, page_url, page_id, act_type, banner_text'\n",
    "        },\n",
    "        {\n",
    "            'page_id': 'life-dev/main',\n",
    "            'click_type': '',\n",
    "            'act_type': 'pageview',\n",
    "            'key_list': 'channel, page_url, page_id, act_type'\n",
    "        },\n",
    "        {\n",
    "            'page_id': 'life-dev/main',\n",
    "            'click_type': 'í€µë²„íŠ¼',\n",
    "            'act_type': 'click',\n",
    "            'key_list': 'channel, page_url, page_id, act_type, click_text, click_type'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Case 2: click_text ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤\n",
    "    sample_data_case2 = [\n",
    "        {\n",
    "            'click_text': 'ë¡œê·¸ì¸ ë²„íŠ¼',\n",
    "            'click_type': 'ë²„íŠ¼',\n",
    "            'act_type': 'click',\n",
    "            'key_list': 'channel, click_text, click_type, act_type, user_id'\n",
    "        },\n",
    "        {\n",
    "            'click_text': 'ìƒí’ˆ ì´ë¯¸ì§€',\n",
    "            'click_type': 'ì´ë¯¸ì§€',\n",
    "            'act_type': 'click',\n",
    "            'key_list': 'channel, click_text, click_type, act_type, product_id'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Case 1 íŒŒì¼ ìƒì„±\n",
    "    df1 = pd.DataFrame(sample_data_case1)\n",
    "    df1.to_csv('scenario_case1.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    # Case 2 íŒŒì¼ ìƒì„±\n",
    "    df2 = pd.DataFrame(sample_data_case2)\n",
    "    df2.to_csv('scenario_case2.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    print(\"âœ… ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ CSV ìƒì„±:\")\n",
    "    print(\"   - scenario_case1.csv (page_id ê¸°ë°˜)\")\n",
    "    print(\"   - scenario_case2.csv (click_text ê¸°ë°˜)\")\n",
    "\n",
    "def run_example():\n",
    "    \"\"\"ì‹¤í–‰ ì˜ˆì‹œ\"\"\"\n",
    "    # ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ CSV ìƒì„±\n",
    "    create_sample_scenario_csv()\n",
    "    \n",
    "    # ê²€ì¦ê¸° ì´ˆê¸°í™”\n",
    "    validator = LogQAValidator()\n",
    "    \n",
    "    # Case 1: page_id ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\n=== Case 1: page_id ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ===\")\n",
    "    validator.load_scenario_csv('scenario_case1.csv')\n",
    "    \n",
    "    # ë¡œê·¸ íŒŒì¼ì—ì„œ ì§ì ‘ íŒŒì‹±\n",
    "    # validator.parse_logs_from_file('log_file.txt')\n",
    "    \n",
    "    # ë˜ëŠ” ë¬¸ìì—´ë¡œ íŒŒì‹± (ì˜ˆì‹œìš©)\n",
    "    log_data = '''\n",
    "{\"REQUEST\":\"https://life-dev.hectoinnovation.co.kr/main?channel\\\\u003dRround\\\\u0026page_url\\\\u003dhttps://life-dev.hectoinnovation.co.kr/main\\\\u0026page_id\\\\u003dlife-dev/main\\\\u0026act_type\\\\u003dimpression\\\\u0026banner_text\\\\u003dì• êµ­ê°€\"}\n",
    "{\"REQUEST\":\"https://life-dev.hectoinnovation.co.kr/main?channel\\\\u003dRround\\\\u0026page_url\\\\u003dhttps://life-dev.hectoinnovation.co.kr/main\\\\u0026page_id\\\\u003dlife-dev/main\\\\u0026act_type\\\\u003dpageview\"}\n",
    "{\"REQUEST\":\"https://life-dev.hectoinnovation.co.kr/main?channel\\\\u003dRround\\\\u0026page_url\\\\u003dhttps://life-dev.hectoinnovation.co.kr/main\\\\u0026page_id\\\\u003dlife-dev/main\\\\u0026act_type\\\\u003dclick\\\\u0026click_text\\\\u003dë¼ìš´ë“œë¡œë˜\\\\u0026click_type\\\\u003dí€µë²„íŠ¼\"}\n",
    "'''\n",
    "    validator.parse_logs(log_data)\n",
    "    \n",
    "    # ê²€ì¦ ë° ê²°ê³¼ ì¶œë ¥\n",
    "    validator.validate_and_export('./result/validation_result_case1.xlsx')\n",
    "    \n",
    "    # Case 2: click_text ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\n=== Case 2: click_text ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ===\")\n",
    "    validator2 = LogQAValidator()\n",
    "    validator2.load_scenario_csv('scenario_case2.csv')\n",
    "    \n",
    "    log_data2 = '''\n",
    "{\"REQUEST\":\"https://example.com/login?channel\\\\u003dWeb\\\\u0026click_text\\\\u003dë¡œê·¸ì¸ ë²„íŠ¼\\\\u0026click_type\\\\u003dë²„íŠ¼\\\\u0026act_type\\\\u003dclick\\\\u0026user_id\\\\u003d123\"}\n",
    "{\"REQUEST\":\"https://example.com/product?channel\\\\u003dWeb\\\\u0026click_text\\\\u003dìƒí’ˆ ì´ë¯¸ì§€\\\\u0026click_type\\\\u003dì´ë¯¸ì§€\\\\u0026act_type\\\\u003dclick\\\\u0026product_id\\\\u003dABC123\"}\n",
    "'''\n",
    "    validator2.parse_logs(log_data2)\n",
    "    validator2.validate_and_export('./result/validation_result_case2.xlsx')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
